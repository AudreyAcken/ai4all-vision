{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data' 'labels']\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('data/assorted_images/satellite_images.h5', 'r')\n",
    "print(np.array(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "raw_data = np.array(f['data'])\n",
    "labels = np.array(f['labels'])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(641, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 224, 224, 3)\n",
      "(33, 224, 224, 3)\n",
      "(32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_ratio, val_ratio = 0.9, 0.05\n",
    "num = raw_data.shape[0]\n",
    "\n",
    "# train_num = int(train_ratio*num)\n",
    "# val_num = int((num-train_num)/2)\n",
    "# test_num = num-train_num-val_num\n",
    "\n",
    "# train_data = raw_data[train_num:]\n",
    "# train_labels = labels[train_num:]\n",
    "# test_data = raw_data[train_num:(train_num+test_num)]\n",
    "# test_labels = labels[train_num:(train_num+test_num)]\n",
    "# val_data = raw_data[:val_num]\n",
    "# val_labels = labels[:val_num]\n",
    "\n",
    "# print(val_data.shape)\n",
    "# print(train_data.shape)\n",
    "# print(test_data.shape)\n",
    "shuffled_ind = np.arange(raw_data.shape[0])\n",
    "np.random.shuffle(shuffled_ind)\n",
    "shuffled_dset = raw_data[shuffled_ind]\n",
    "shuffled_lset = labels[shuffled_ind]\n",
    "\n",
    "train_data = shuffled_dset[:int(raw_data.shape[0]*train_ratio), ...]\n",
    "train_labels = shuffled_lset[:int(raw_data.shape[0]*train_ratio), ...]\n",
    "\n",
    "val_data = shuffled_dset[int(raw_data.shape[0]*train_ratio):int(raw_data.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "val_labels = shuffled_lset[int(raw_data.shape[0]*train_ratio):int(raw_data.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "\n",
    "test_data = shuffled_dset[int(raw_data.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "test_labels = shuffled_lset[int(raw_data.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0710 16:08:52.978844 140737168323520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential # Sequential is one of the main models in Keras, which is basically a sequentially stacked series of layers\n",
    "\n",
    "model = Sequential() # Initialize a Sequential model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0710 16:08:53.034721 140737168323520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0710 16:08:53.051466 140737168323520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0710 16:08:53.096162 140737168323520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0710 16:08:53.117784 140737168323520 deprecation.py:506] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# First we'll use fully-connected neural nets\n",
    "from keras.layers import Dense # Dense is Keras's name for fully connected layers\n",
    "\n",
    "# We can stack layers like lego blocks by simplying using `add()`\n",
    "# `units` is the number of neurons\n",
    "# `activation` is the nonlinear function we add for each layer\n",
    "# We only need to specify `input_dim` which is the input dimension for the layer for the input layer, because for later layers the input is just the output from last layer\n",
    "# Once again, the number of neurons in hidden layers (e.g., 64 and 16 here) are design choices\n",
    "\n",
    "model.add(Dense(units=64, activation='sigmoid', input_dim=224*224*3)) \n",
    "model.add(keras.layers.Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(Dense(units=16, activation='sigmoid'))\n",
    "model.add(keras.layers.Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0710 16:08:53.224805 140737168323520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0710 16:08:53.262505 140737168323520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0710 16:08:53.273715 140737168323520 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Once the model is build, we then configure the learning process with `compile()`\n",
    "# We need to specify the loss function, the optimizer and the metric we use to evaluate our model\n",
    "# For loss here we're using a function called binary cross-entropy loss, which is specifically for binary classification\n",
    "# For optimizer we're using gradient descent, which is written as 'sgd' in Keras\n",
    "# Since we're doing classification, normally the classification accuracy is how we evaluate the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 150528)\n",
      "(33, 150528)\n",
      "(32, 150528)\n",
      "Train on 576 samples, validate on 32 samples\n",
      "Epoch 1/30\n",
      "576/576 [==============================] - 3s 5ms/step - loss: 0.8370 - acc: 0.4115 - val_loss: 0.7243 - val_acc: 0.2188\n",
      "Epoch 2/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.7357 - acc: 0.5000 - val_loss: 0.6199 - val_acc: 0.7812\n",
      "Epoch 3/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.6317 - acc: 0.6319 - val_loss: 0.5785 - val_acc: 0.7812\n",
      "Epoch 4/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5840 - acc: 0.6858 - val_loss: 0.5552 - val_acc: 0.7812\n",
      "Epoch 5/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5814 - acc: 0.7205 - val_loss: 0.5420 - val_acc: 0.7812\n",
      "Epoch 6/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5793 - acc: 0.7326 - val_loss: 0.5356 - val_acc: 0.7812\n",
      "Epoch 7/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5695 - acc: 0.7552 - val_loss: 0.5315 - val_acc: 0.7812\n",
      "Epoch 8/30\n",
      "576/576 [==============================] - 2s 4ms/step - loss: 0.5723 - acc: 0.7587 - val_loss: 0.5293 - val_acc: 0.7812\n",
      "Epoch 9/30\n",
      "576/576 [==============================] - 2s 4ms/step - loss: 0.5587 - acc: 0.7639 - val_loss: 0.5273 - val_acc: 0.7812\n",
      "Epoch 10/30\n",
      "576/576 [==============================] - 2s 4ms/step - loss: 0.5685 - acc: 0.7674 - val_loss: 0.5265 - val_acc: 0.7812\n",
      "Epoch 11/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5672 - acc: 0.7656 - val_loss: 0.5261 - val_acc: 0.7812\n",
      "Epoch 12/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5555 - acc: 0.7795 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 13/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5467 - acc: 0.7812 - val_loss: 0.5253 - val_acc: 0.7812\n",
      "Epoch 14/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5771 - acc: 0.7795 - val_loss: 0.5253 - val_acc: 0.7812\n",
      "Epoch 15/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5526 - acc: 0.7726 - val_loss: 0.5253 - val_acc: 0.7812\n",
      "Epoch 16/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5578 - acc: 0.7691 - val_loss: 0.5253 - val_acc: 0.7812\n",
      "Epoch 17/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5462 - acc: 0.7795 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 18/30\n",
      "576/576 [==============================] - 2s 4ms/step - loss: 0.5375 - acc: 0.7830 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 19/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5543 - acc: 0.7795 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 20/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5468 - acc: 0.7691 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 21/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5522 - acc: 0.7812 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 22/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5552 - acc: 0.7812 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 23/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5456 - acc: 0.7847 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 24/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5452 - acc: 0.7865 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 25/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5413 - acc: 0.7865 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 26/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5568 - acc: 0.7865 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 27/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5448 - acc: 0.7847 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 28/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5491 - acc: 0.7865 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 29/30\n",
      "576/576 [==============================] - 2s 4ms/step - loss: 0.5423 - acc: 0.7830 - val_loss: 0.5254 - val_acc: 0.7812\n",
      "Epoch 30/30\n",
      "576/576 [==============================] - 2s 3ms/step - loss: 0.5362 - acc: 0.7847 - val_loss: 0.5254 - val_acc: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb48f89630>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Up to this point we're all doing configurations. Now everything is set up so we're letting the model do real things!\n",
    "\n",
    "# Since now we're using a fully-connected nets, remember we need to flatten the image to a single long vector first\n",
    "train_data = train_data.reshape((-1, 224*224*3)) # -1 means letting NumPy to figure this axis out automatically\n",
    "test_data = test_data.reshape((-1, 224*224*3))\n",
    "val_data = val_data.reshape((-1, 224*224*3))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)\n",
    "\n",
    "# Then use fit() to actually train our model\n",
    "# epochs is basically how many iterations we want for the update process. The model needs some time to reach the optimal state!\n",
    "# batch_size is how many images we use each time to estimate the gradient. Remember that the more we use the more accurate each update will be, but it will also be slower\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=30, batch_size=32, validation_data=(val_data, val_labels), shuffle=True)\n",
    "#epochs - how many iterations\n",
    "#batch size - sgd batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 1ms/step\n",
      "The test accuracy is: [0.47713189414053253, 0.8181818181818182]\n",
      "The predicted probabilities are: [[0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289304]\n",
      " [0.21289305]]\n",
      "The predicted class labels are: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's see how our model does\n",
    "acc = model.evaluate(test_data, test_labels)\n",
    "print('The test accuracy is: {}'.format(acc))\n",
    "\n",
    "# And make predictions\n",
    "prob = model.predict(test_data) # These are probabilities, and we want to convert them to class labels\n",
    "label = np.array(prob > 0.5, dtype=int)\n",
    "\n",
    "print('The predicted probabilities are: {}'.format(prob))\n",
    "print('The predicted class labels are: {}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
