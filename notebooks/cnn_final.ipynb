{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "f = h5py.File('data/assorted_images/satellite_images.h5', 'r')\n",
    "print(np.array(f))\n",
    "raw_data = np.array(f['data'])\n",
    "raw_labels = np.array(f['labels'])\n",
    "print(raw_labels)\n",
    "inds_0 = []\n",
    "inds_1 = []\n",
    "for i in range(len(raw_labels)):\n",
    "    if raw_labels[i] == 1:\n",
    "        inds_1.append(i)\n",
    "    if raw_labels[i] == 0:\n",
    "        inds_0.append(i)\n",
    "\n",
    "np.random.shuffle(inds_0)\n",
    "inds_0 = inds_0[:136]\n",
    "data_0 = raw_data[inds_0]\n",
    "labels_0 = raw_labels[inds_0]\n",
    "# print(data_0)\n",
    "print(labels_0)\n",
    "print(data_0.shape)\n",
    "print(labels_0.shape)\n",
    "data_1 = raw_data[inds_1]\n",
    "labels_1 = raw_labels[inds_1]\n",
    "# print(data_1)\n",
    "print(labels_1)\n",
    "print(data_1.shape)\n",
    "print(labels_1.shape)\n",
    "\n",
    "# append 0s and 1s\n",
    "data = np.append(data_0, data_1, axis=0)\n",
    "print(\"data: \", data.shape)\n",
    "labels = np.append(labels_0, labels_1)\n",
    "print(\"labels: \", labels.shape)\n",
    "\n",
    "# shuffle combined\n",
    "shuffled_ind = np.arange(data.shape[0])\n",
    "np.random.shuffle(shuffled_ind)\n",
    "data = data[shuffled_ind]\n",
    "labels = labels[shuffled_ind]\n",
    "\n",
    "print(data.shape)\n",
    "train_ratio, val_ratio = 0.8, 0.1\n",
    "\n",
    "train_data = data[:int(data.shape[0]*train_ratio), ...]\n",
    "train_labels = labels[:int(labels.shape[0]*train_ratio), ...]\n",
    "\n",
    "test_data = data[int(data.shape[0]*train_ratio):int(data.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "test_labels = labels[int(labels.shape[0]*train_ratio):int(labels.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "\n",
    "val_data = data[int(data.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "val_labels = labels[int(labels.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "\n",
    "print(labels)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File('data/assorted_images/satellite_images.h5', 'r')\n",
    "# print(np.array(f))\n",
    "# raw_data = np.array(f['data'])\n",
    "# labels = np.array(f['labels'])\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(raw_data.shape)\n",
    "# train_ratio, val_ratio = 0.9, 0.05\n",
    "\n",
    "# train_data = raw_data[:int(raw_data.shape[0]*train_ratio), ...] # ... means all the other axes\n",
    "# train_labels = labels[:int(labels.shape[0]*train_ratio), ...]\n",
    "\n",
    "# test_data = raw_data[int(raw_data.shape[0]*train_ratio):int(raw_data.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "# test_labels = labels[int(labels.shape[0]*train_ratio):int(labels.shape[0]*(train_ratio+val_ratio)), ...]\n",
    "\n",
    "# val_data = raw_data[int(raw_data.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "# val_labels = labels[int(labels.shape[0]*(train_ratio+val_ratio)):, ...]\n",
    "\n",
    "# print(train_data.shape)\n",
    "# print(test_data.shape)\n",
    "# print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = [10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 3*10**-3, 10**-2, 3*10**-2]\n",
    "# layers = [2, 3, 4, 5]\n",
    "# CNN_layers = [2,3]\n",
    "# neurons = [8, 16, 32, 64]\n",
    "# learning_rate = [10**-5]\n",
    "layers = [2]\n",
    "CNN_layers = [2]\n",
    "neurons = [8]\n",
    "\n",
    "for rate in learning_rate:\n",
    "    for num in layers:\n",
    "        for n in neurons:\n",
    "            for c in CNN_layers:\n",
    "                print(rate, num, n, c)\n",
    "                model = Sequential()\n",
    "                \n",
    "                for i in range(c):\n",
    "\n",
    "                    model.add(keras.layers.Conv2D(filters=16, kernel_size=3, strides=(2, 2), padding='same'))\n",
    "                    model.add(keras.layers.Activation('relu'))\n",
    "                    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) # By default the stride is the same as the pooling size\n",
    "\n",
    "                model.add(keras.layers.Flatten())\n",
    "\n",
    "                for i in range(0, num-1):\n",
    "                    model.add(keras.layers.Dense(n))\n",
    "                    model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "                model.add(keras.layers.Dense(1))\n",
    "                model.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "                model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=rate), metrics=['accuracy'])\n",
    "                history = model.fit(train_data, train_labels, epochs=30, batch_size=32, validation_data=(val_data, val_labels), shuffle=True)\n",
    "                loss, acc = model.evaluate(test_data, test_labels)\n",
    "                print('The test accuracy is: {}'.format(acc))\n",
    "\n",
    "                plt.plot(history.history['loss'])\n",
    "                plt.plot(history.history['val_loss'])\n",
    "                plt.title('Model loss')\n",
    "                plt.ylabel('loss')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.legend(['Train', 'Val'], loc='upper left')\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(history.history['acc'])\n",
    "                plt.plot(history.history['val_acc'])\n",
    "                plt.title('Model accuracy')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.legend(['Train', 'Val'], loc='upper left')\n",
    "                plt.show()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # As we can expect, the results are totally random\n",
    "# # You can also play with other models, e.g., convnets\n",
    "# # So we do the same procedure once more\n",
    "\n",
    "# model = Sequential() # Re-initialize the model\n",
    "\n",
    "# # Feature extractor\n",
    "# # We're using such an architecture: conv -> maxpool -> conv -> maxpool\n",
    "# # 'same' padding means we zero-pad the images so that the output will be of the same size as the input\n",
    "# model.add(keras.layers.Conv2D(filters=16, kernel_size=3, strides=(2, 2), padding='same'))\n",
    "# model.add(keras.layers.Activation('sigmoid'))\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2, 2))) # By default the stride is the same as the pooling size\n",
    "\n",
    "# model.add(keras.layers.Conv2D(filters=32, kernel_size=2, strides=(1, 1), padding='same'))\n",
    "# model.add(keras.layers.Activation('relu')) # ReLU is another kind of non-linear function\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # Classifier\n",
    "# # We're using a 2-layer FC net for classification \n",
    "# model.add(keras.layers.Flatten()) #flatten before fully connected part\n",
    "\n",
    "# model.add(keras.layers.Dense(16))\n",
    "# model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "# model.add(keras.layers.Dense(8))\n",
    "# model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "# model.add(keras.layers.Dense(1))\n",
    "# model.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "# # Compilation\n",
    "# model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "#model.fit(train_data, train_labels, epochs=30, batch_size=32, validation_data=(val_data, val_labels), shuffle=True)\n",
    "history = model.fit(train_data, train_labels, epochs=5, batch_size=32, validation_data=(val_data, val_labels), shuffle=True)\n",
    "print('\\n', history.history.keys())\n",
    "# Evaluation\n",
    "acc = model.evaluate(test_data, test_labels)\n",
    "print('The test accuracy is: {}'.format(acc))\n",
    "\n",
    "# And make predictions\n",
    "prob = model.predict(test_data) # These are probabilities, and we want to convert them to class labels\n",
    "label = np.array(prob > 0.5, dtype=int)\n",
    "\n",
    "print('The predicted probabilities are: {}'.format(prob))\n",
    "print('The predicted class labels are: {}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "print(np.count_nonzero(a == 1))\n",
    "print(np.count_nonzero(a == 0))\n",
    "\n",
    "\n",
    "    \n",
    "# a = np.load('./data/survey_data/uga_2011_labels.npy')\n",
    "# b = np.loadtxt('./data/survey_data/uga_2011_locs.txt')\n",
    "\n",
    "# for i in range(len(b)):\n",
    "#     if a[i] == 0:\n",
    "#         print(b[i], '<default-dot>')\n",
    "#     elif a[i] == 1:\n",
    "#         print(b[i], '<green-dot>')\n",
    "\n",
    "path = './data/satellite_images/'\n",
    "img_list = os.listdir(path) # image data\n",
    "print(len(img_list))\n",
    "\n",
    "for i in range(10):\n",
    "    img = Image.open(path + img_list[i])\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype='int')\n",
    "    plt.imshow(data)\n",
    "    print(data.shape)\n",
    "    break\n",
    "\n",
    "a = np.load('./data/survey_data/uga_2011_labels.npy') # labels\n",
    "\n",
    "# a is the array of labels and data is the list of images\n",
    "# so then write:\n",
    "\n",
    "inds = []\n",
    "for i in range(len(a)):\n",
    "    if a[i] == 0:\n",
    "        inds.append(i)\n",
    "\n",
    "sampled_inds = np.random.shuffle(inds)\n",
    "inds = inds[:136]\n",
    "print(inds)\n",
    "    \n",
    "img_list = np.array(img_list)\n",
    "print(img_list[inds])\n",
    "print(a[inds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
